{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice Detection Project\n",
    "Dice detection project for Computer Vision (include description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import kagglehub\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"nellbyler/d6-dice\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# ANNOTATION_PATH = path + \"/d6-dice/Annotations\"\n",
    "# IMAGE_PATH = path + \"/d6-dice/Images\"\n",
    "\n",
    "ANNOTATION_PATH = os.path.join(path, \"d6-dice\", \"Annotations\")\n",
    "IMAGE_PATH = os.path.join(path, \"d6-dice\", \"Images\")\n",
    "\n",
    "# windows delim\n",
    "split_char = '\\\\'\n",
    "\n",
    "# linux delim\n",
    "#split_char = '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anotation_files = []\n",
    "for dir,_,files in os.walk(ANNOTATION_PATH):\n",
    "    for filename in files:\n",
    "        if filename[-4:] == '.txt':\n",
    "            anotation_files += [(os.path.join(dir,filename))]\n",
    "\n",
    "# remove classes.txt file from image pool\n",
    "anotation_files.pop(0)\n",
    "\n",
    "# 70/15/15 train-test split\n",
    "train_ratio = .7\n",
    "test_ratio = (1.0 - train_ratio) / 2\n",
    "valid_ratio = test_ratio\n",
    "\n",
    "SIZE = len(anotation_files)\n",
    "N = list(range(SIZE))\n",
    "\n",
    "train_size = int(SIZE * train_ratio)\n",
    "test_size = int(SIZE * test_ratio)\n",
    "valid_size = int(SIZE * valid_ratio)\n",
    "\n",
    "# Add any files that might have been accidentally skipped to the train set\n",
    "while((train_size + test_size + valid_size) < len(anotation_files)):\n",
    "    train_size += 1\n",
    "\n",
    "print(train_size)\n",
    "print(test_size)\n",
    "print(valid_size)\n",
    "print(len(anotation_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Organize and prep data for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs('datasets/train/images', exist_ok=True)\n",
    "os.makedirs('datasets/train/labels', exist_ok=True)\n",
    "\n",
    "os.makedirs('datasets/test/images', exist_ok=True)\n",
    "os.makedirs('datasets/test/labels', exist_ok=True)\n",
    "\n",
    "os.makedirs('datasets/valid/images', exist_ok=True)\n",
    "os.makedirs('datasets/valid/labels', exist_ok=True)\n",
    "\n",
    "# helper to organize files into their respective directories\n",
    "def copy_files(i, dir, ano_files):\n",
    "    # get the image filename\n",
    "    ano_file = ano_files[i]\n",
    "    img_file = ano_file.split(split_char)[-1][0:-4] + '.jpg'\n",
    "\n",
    "    # copy into folders\n",
    "    shutil.copy(ano_file, dir + '/labels')\n",
    "    shutil.copy(os.path.join(IMAGE_PATH, img_file), os.path.join(dir + '/images/', img_file))\n",
    "\n",
    "# copy image and label files into local directories\n",
    "for i in range(train_size):\n",
    "    copy_files(i, './datasets/train', anotation_files)\n",
    "\n",
    "test_start = train_size + valid_size\n",
    "test_end = test_start + test_size\n",
    "for i in range(test_start, test_end):\n",
    "    copy_files(i, './datasets/test', anotation_files)\n",
    "\n",
    "\n",
    "valid_start = train_size\n",
    "valid_end = valid_start + valid_size\n",
    "for i in range(valid_start, valid_end):\n",
    "    copy_files(i, './datasets/valid', anotation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "source_path = current_directory = os.getcwd()\n",
    "\n",
    "train_path = os.path.join(source_path, \"datasets\", \"train\")\n",
    "test_path = os.path.join(source_path, \"datasets\", \"test\")\n",
    "valid_path = os.path.join(source_path, \"datasets\", \"valid\")\n",
    "\n",
    "data_yaml = dict(\n",
    "    train = train_path,\n",
    "    test = test_path,\n",
    "    val = valid_path,\n",
    "    \n",
    "    nc = 6,\n",
    "    names = list('123456'),\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "with open('data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = YOLO(\"yolo11x.pt\")  # build from YAML and transfer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.train(\n",
    "    data = \"./data.yaml\",\n",
    "    epochs = 12,\n",
    "    imgsz = 480\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset_path = kagglehub.dataset_download(\"koryakinp/d6-dices-images\")\n",
    "\n",
    "dataset_images = os.path.join(pred_dataset_path, \"dataset-images\")\n",
    "\n",
    "print(pred_dataset_path)\n",
    "\n",
    "image_dir = os.listdir(os.path.join(pred_dataset_path, 'dataset-images'))\n",
    "image_list = []\n",
    "for file in image_dir:\n",
    "    image_list.append(os.path.join(pred_dataset_path,'dataset-images', file))\n",
    "\n",
    "print(image_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('test_images/masked_images', exist_ok=True)\n",
    "\n",
    "def save_im(image_path, result):\n",
    "    cv2.imwrite(image_path, result)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i in range(len(image_list)):\n",
    "        image = cv2.imread(image_list[i])\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        _, dice_mask = cv2.threshold(gray_image, 125, 255, cv2.THRESH_BINARY_INV)\n",
    "        result = cv2.bitwise_and(image, image, mask=dice_mask)\n",
    "        result[dice_mask == 0] = [255, 255, 255]\n",
    "        result[dice_mask != 0] = [0, 0, 0]\n",
    "\n",
    "        #plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        #plt.axis(\"off\")\n",
    "        #plt.title(\"Masked Dice\")\n",
    "        #plt.show()\n",
    "        #masked_images.append(result)\n",
    "\n",
    "        image_name = 'masked_image'+str(i)+'.jpg'\n",
    "\n",
    "        im_name = os.path.join('test_images', 'masked_images', image_name)\n",
    "        masked_images.append(im_name)\n",
    "\n",
    "        # output to file\n",
    "        futures.append(executor.submit(save_im, im_name, result))\n",
    "\n",
    "    # wait to retrieve all futures\n",
    "    for future in futures:\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_path):\n",
    "    # Load the image from the directory\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "show_image(image_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict Using a Different Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(results, image_list, file_name):\n",
    "    keys = [0, 1, 2, 3, 4, 5]\n",
    "    values = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    image_list = sorted(image_list)\n",
    "\n",
    "    class_dict = dict(zip(keys, values))\n",
    "\n",
    "    data = pd.DataFrame(columns= range(6))\n",
    "    for i in range(len(results)):\n",
    "        # add the data to a Data Frame\n",
    "        result = pd.DataFrame(results[i].boxes.data.cpu().numpy()).astype(float)\n",
    "        \n",
    "        # append the \n",
    "        file = image_list[i]\n",
    "        result['img index'] = int(i)\n",
    "        result['file'] = file\n",
    "\n",
    "        data = pd.concat([data, result], axis=0)\n",
    "\n",
    "    # rename columns\n",
    "    data.columns = ['x', 'y', 'x2', 'y2', 'cl', 'label', 'i', 'file']\n",
    "\n",
    "    # apply correct labellings\n",
    "    data['label'] = data['label'].map(class_dict)\n",
    "    data['i'] = data['i'].astype(int)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # output data\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    data.to_csv(os.path.join(\"results\", \"data\", file_name + \".csv\"), index=False, header=True)\n",
    "\n",
    "    display(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_list[21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict bounding boxes and values of the dice in another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = YOLO(os.path.join(\"runs\", \"detect\", \"train4\", \"weights\", \"best.pt\"))\n",
    "#trained_model_e20 = YOLO(os.path.join(\"runs\", \"detect\", \"train\", \"weights\", \"best.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with epoch = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trained_model.predict(source=image_list[:20], conf=0.2)\n",
    "results_masked = trained_model.predict(source=masked_images[:20], conf=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with epoch=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_e20 = trained_model_e20.predict(source=image_list[:20], conf=0.2)\n",
    "#results_e20_masked = trained_model_e20.predict(source=masked_images[:20], conf=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(\"results\",\"data\"), exist_ok=True)\n",
    "\n",
    "orig_df = get_results(results, image_list, \"orig_e12\")\n",
    "masked_df = get_results(results_masked, masked_images, \"masked_e12\")\n",
    "\n",
    "#orig_df_e20 = get_results(results_e20, image_list, \"orig_e20\")\n",
    "#masked_df_e20 = get_results(results_e20_masked, masked_images, \"masked_e20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Remove duplicate bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coincides(b1, b2, scale=0.1):\n",
    "    # bounding box (BB) 1 diagonal length\n",
    "    p1 = np.array([b1[0], b1[1]])\n",
    "    p2 = np.array([b1[2], b1[3]])\n",
    "    threshold = np.linalg.norm(p1 - p2) * scale\n",
    "\n",
    "    # distance between BB 1 and BB 2\n",
    "    p1 = np.array([b1[0], b1[1]])\n",
    "    p2 = np.array([b2[0], b2[1]])\n",
    "    dist = np.linalg.norm(p1 - p2)\n",
    "    \n",
    "    return dist < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of Extra Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare bounding boxes\n",
    "def compare_boxes(data, cl):\n",
    "    remove_idx = []\n",
    "    for i in range(len(data)):\n",
    "        # if data was already removed, then skip\n",
    "        if i in remove_idx:\n",
    "            continue\n",
    "        \n",
    "        # obtain first bounding box\n",
    "        b1 = data[i]\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            # if data was already removed, then skip\n",
    "            if j in remove_idx:\n",
    "                continue\n",
    "\n",
    "            # obtain second bounding box\n",
    "            b2 = data[j]\n",
    "\n",
    "            if np.array_equiv(b1, b2):\n",
    "                continue\n",
    "            \n",
    "            # if 2 bounding boxes coincide, then take the value with the higher confidence level\n",
    "            if coincides(b1, b2, .05):\n",
    "                remove_idx.append(j if cl[i] > cl[j] else i)\n",
    "    \n",
    "    return remove_idx\n",
    "\n",
    "# remove any duplicate bounding boxes\n",
    "def remove_dup_BB(df):\n",
    "    max_index = df.iloc[-1]['i'] + 1\n",
    "\n",
    "    offset = 0\n",
    "    remove_idx = []\n",
    "    for index in range(max_index):\n",
    "        # remove the label, confidence level, image index, and image path\n",
    "        view = df[df['i'] == index].iloc[:, :-4]\n",
    "        cl = df[df['i'] == index]['cl']\n",
    "        cl = cl.reset_index(drop=True)\n",
    "\n",
    "        # remove duplicate bounding boxes\n",
    "        dup_idx = compare_boxes(view.to_numpy(), cl)\n",
    "        dup_idx = [i + offset for i in dup_idx]\n",
    "\n",
    "        remove_idx.extend(dup_idx)\n",
    "\n",
    "        # increment offset\n",
    "        offset = offset + len(view)\n",
    "\n",
    "    # filter out wrong bounding boxes\n",
    "    if remove_idx:\n",
    "        filtered_df = df.drop(remove_idx)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(\"results\",\"filtered\"), exist_ok=True)\n",
    "\n",
    "filtered_orig_e12_df = remove_dup_BB(orig_df)\n",
    "filtered_orig_e12_df.to_csv(os.path.join(\"results\", \"filtered\", \"filtered_orig.csv\"), index=False, header=True)\n",
    "\n",
    "#filtered_orig_e20_df = remove_dup_BB(orig_df_e20)\n",
    "#filtered_orig_e20_df.to_csv(os.path.join(\"results\", \"filtered\", \"filtered_orig_e20.csv\"), index=False, header=True)\n",
    "\n",
    "filtered_mask_e12_df = remove_dup_BB(masked_df)\n",
    "filtered_mask_e12_df.to_csv(os.path.join(\"results\", \"filtered\", \"filtered_masked.csv\"), index=False, header=True)\n",
    "\n",
    "#filtered_mask_e20_df = remove_dup_BB(masked_df_e20)\n",
    "#filtered_mask_e20_df.to_csv(os.path.join(\"results\", \"filtered\", \"filtered_masked_e20.csv\"), index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show removed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display difference\n",
    "def show_diff(orig, filt):\n",
    "    display(pd.concat([orig, filt]).drop_duplicates(keep=False))\n",
    "\n",
    "print(\"epoch=12\")\n",
    "show_diff(orig_df, filtered_orig_e12_df)\n",
    "show_diff(masked_df, filtered_mask_e12_df)\n",
    "\n",
    "#print(\"epoch=20\")\n",
    "#show_diff(orig_df_e20, filtered_orig_e20_df)\n",
    "#show_diff(masked_df_e20, filtered_mask_e20_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "i = 0\n",
    "\n",
    "roll_map = {1:0,\n",
    "            2:0,\n",
    "            3:0,\n",
    "            4:0,\n",
    "            5:0,\n",
    "            6:0}\n",
    "for file,label in zip(orig_df['i'], orig_df['label']):\n",
    "    if(file!=i):\n",
    "        i = file\n",
    "        #print(roll_map)\n",
    "        dict_list.append(roll_map)\n",
    "        roll_map = {1:0,\n",
    "                    2:0,\n",
    "                    3:0,\n",
    "                    4:0,\n",
    "                    5:0,\n",
    "                    6:0}\n",
    "        continue\n",
    "    roll_map[label]+=1\n",
    "dict_list.append(roll_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Use PIL for image handling\n",
    "\n",
    "rolls = dict_list[9]\n",
    "image_path = image_list[9]\n",
    "sum = rolls[1] + rolls[2]*2 + rolls[3]*3 + rolls[4]*4 + rolls[5]*5 + rolls[6]*6\n",
    "\n",
    "data = [[\"1's\", rolls[1]],\n",
    "        [\"2's\", rolls[2]],\n",
    "        [\"3's\", rolls[3]],\n",
    "        [\"4's\", rolls[4]],\n",
    "        [\"5's\", rolls[5]],\n",
    "        [\"6's\", rolls[6]],\n",
    "        [\"SUM\", sum]]\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Table with Image Example\")\n",
    "\n",
    "# Create a style for the Treeview\n",
    "style = ttk.Style()\n",
    "style.configure(\"Treeview\", font=(\"Helvetica\", 14))\n",
    "style.configure(\"Treeview.Heading\", font=(\"Helvetica\", 16, \"bold\"))\n",
    "\n",
    "# Frame to hold the table and image\n",
    "main_frame = tk.Frame(root)\n",
    "main_frame.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "# Add a treeview for the table\n",
    "table_frame = tk.Frame(main_frame)\n",
    "table_frame.pack(side=tk.LEFT, expand=True, fill=tk.BOTH, padx=10, pady=10)\n",
    "\n",
    "columns = [\"Dice #\", \"Roll count\"]\n",
    "tree = ttk.Treeview(table_frame, columns=columns, show=\"headings\")\n",
    "for col in columns:\n",
    "    tree.heading(col, text=col)\n",
    "    tree.column(col, width=120, anchor=\"center\")\n",
    "\n",
    "for row in data:\n",
    "    tree.insert(\"\", tk.END, values=row)\n",
    "\n",
    "tree.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "# Add an image to the side\n",
    "image_frame = tk.Frame(main_frame)\n",
    "image_frame.pack(side=tk.RIGHT, padx=10, pady=10)\n",
    "\n",
    "try:\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((250, 250))  # Resize the image to fit\n",
    "    tk_img = ImageTk.PhotoImage(img)\n",
    "\n",
    "    # Display the image in a Label and keep the reference\n",
    "    image_label = tk.Label(image_frame, image=tk_img)\n",
    "    image_label.image = tk_img  # Keep a reference to avoid garbage collection\n",
    "    image_label.pack()\n",
    "except FileNotFoundError:\n",
    "    image_label = tk.Label(image_frame, text=\"Image not found\", font=(\"Helvetica\", 14))\n",
    "    image_label.pack()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")  # Debugging fallback\n",
    "\n",
    "# Start the application\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
