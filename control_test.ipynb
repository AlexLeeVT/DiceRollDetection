{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code sourced from: <br>\n",
    "https://www.kaggle.com/code/stpeteishii/dice-yolov8-train-and-predict-2#Create-yaml-file\n",
    "<br>\n",
    "\n",
    "used solely for testing purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\samal\\.cache\\kagglehub\\datasets\\nellbyler\\d6-dice\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nellbyler/d6-dice\")\n",
    "\n",
    "ANNOTATION_PATH = path + \"\\\\d6-dice\\\\Annotations\"\n",
    "IMAGES_PATH = path + \"\\\\d6-dice\\\\Images\"\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.39  Python-3.11.9 torch-2.5.1+cpu CPU (AMD Ryzen 7 5800X 8-Core Processor)\n",
      "Setup complete  (16 CPUs, 31.9 GB RAM, 813.5/930.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "from PIL import Image\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'datasets/train/'\n",
    "valid_path = 'datasets/valid/'\n",
    "test_path = 'datasets/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# print(os.path.join(path, '/kaggle/input/d6-dice/d6-dice/Annotations'))\n",
    "\n",
    "\n",
    "ano_paths=[]\n",
    "for dirname, _, filenames in os.walk(ANNOTATION_PATH):\n",
    "    for filename in filenames:\n",
    "        if filename[-4:]=='.txt':\n",
    "            ano_paths+=[(os.path.join(dirname, filename))]\n",
    "\n",
    "ano_paths.pop(0);\n",
    "\n",
    "n=len(ano_paths) \n",
    "print(n)\n",
    "N=list(range(n))\n",
    "random.shuffle(N)\n",
    "\n",
    "train_ratio = 0.6\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_size = int(train_ratio*n)\n",
    "valid_size = int(valid_ratio*n)\n",
    "\n",
    "train_i = N[:train_size]\n",
    "valid_i = N[train_size:train_size+valid_size]\n",
    "test_i = N[train_size+valid_size:]\n",
    "\n",
    "# print(len(train_i))\n",
    "# print(len(valid_i))\n",
    "# print(len(test_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('datasets/train/images'):\n",
    "    os.makedirs('datasets/train/images')\n",
    "if not os.path.exists('datasets/valid/images'):\n",
    "    os.makedirs('datasets/valid/images')\n",
    "if not os.path.exists('datasets/test/images'):\n",
    "    os.makedirs('datasets/test/images')\n",
    "if not os.path.exists('datasets/train/labels'):\n",
    "    os.makedirs('datasets/train/labels')\n",
    "if not os.path.exists('datasets/valid/labels'):\n",
    "    os.makedirs('datasets/valid/labels')\n",
    "if not os.path.exists('datasets/test/labels'):\n",
    "    os.makedirs('datasets/test/labels')\n",
    "\n",
    "delim = '\\\\'\n",
    "\n",
    "for i in train_i:\n",
    "    ano_path=ano_paths[i]\n",
    "    img_path=os.path.join(IMAGES_PATH,\n",
    "                          ano_path.split(delim)[-1][0:-4]+'.jpg')\n",
    "    \n",
    "    shutil.copy(ano_path, os.path.join(train_path + \"\\\\labels\\\\\", os.path.basename(ano_path)))\n",
    "    shutil.copy(img_path, os.path.join(train_path + \"\\\\images\\\\\", os.path.basename(img_path)))\n",
    "\n",
    "for i in valid_i:\n",
    "    ano_path=ano_paths[i]\n",
    "    img_path=os.path.join(IMAGES_PATH,\n",
    "                          ano_path.split(delim)[-1][0:-4]+'.jpg')\n",
    "    \n",
    "    shutil.copy(ano_path, os.path.join(valid_path + \"\\\\labels\\\\\", os.path.basename(ano_path)))\n",
    "    shutil.copy(img_path, os.path.join(valid_path + \"\\\\images\\\\\", os.path.basename(img_path)))\n",
    "\n",
    "for i in test_i:\n",
    "    ano_path=ano_paths[i]\n",
    "    img_path=os.path.join(IMAGES_PATH,\n",
    "                          ano_path.split(delim)[-1][0:-4]+'.jpg')\n",
    "    \n",
    "    shutil.copy(ano_path, os.path.join(test_path + \"\\\\labels\\\\\", os.path.basename(ano_path)))\n",
    "    shutil.copy(img_path, os.path.join(test_path + \"\\\\images\\\\\", os.path.basename(img_path)))\n",
    "\n",
    "\n",
    "# def count_files_in_subdirectories(path):\n",
    "#     total_files = 0\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         total_files += len(files)\n",
    "#     return total_files\n",
    "\n",
    "# print(\"Number of files in train directory:\", count_files_in_subdirectories(train_path))\n",
    "# print(\"Number of files in valid directory:\", count_files_in_subdirectories(valid_path))\n",
    "# print(\"Number of files in test directory:\", count_files_in_subdirectories(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "source_path = 'C:\\\\Users\\\\samal\\\\Computer-vision-project\\\\DiceRollDetection'\n",
    "#source_path = 'C:\\\\Users\\\\leeal\\\\OneDrive - Virginia Tech\\\\School\\\\Computer Vision\\\\DiceRollDetection'\n",
    "\n",
    "train_path = source_path+'\\\\datasets\\\\train'\n",
    "test_path = source_path+'\\\\datasets\\\\test'\n",
    "valid_path = source_path+'\\\\datasets\\\\valid'\n",
    "\n",
    "data_yaml = dict(\n",
    "    train =train_path,\n",
    "    val =valid_path,\n",
    "    test=test_path,\n",
    "    nc =6,\n",
    "    names =list('123456')\n",
    ")\n",
    "\n",
    "with open('data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =list('123456')\n",
    "M=list(range(len(names)))\n",
    "class_map=dict(zip(M,names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8x.pt data=data.yaml epochs=12 imgsz=480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
